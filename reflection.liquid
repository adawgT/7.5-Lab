---
title: "AI Tool Reflection"
layout: "layout.liquid"
---

<h1 class="text-3xl font-bold mb-6 text-center">Reflection on AI Tools</h1>

<div class="bg-white p-6 rounded-lg shadow-md">
  <p>
    During this project, I tested different AI-powered coding assistants, including <strong>GitHub Copilot</strong> and <strong>GPT-4o</strong>, to help with integrating Alpine.js, 11ty, and an external JSON API. The AI tools were helpful for quickly generating boilerplate code and structuring my Alpine.js components, but they also had limitations, particularly with script placement and 11ty-specific configurations.
  </p>

  <p class="mt-4">
    One of the biggest advantages of using AI was its ability to generate quick and functional API fetch examples. For instance, when I asked, <em>"How do I fetch and display JSONPlaceholder users using Alpine.js?"</em>, GPT-4o provided a working example with `x-data` and `x-init`. However, it initially used `fetch()` inside an inline script rather than leveraging Alpine stores, which I later corrected. On the other hand, GitHub Copilot was better at suggesting inline Tailwind classes when I prompted, <em>"Style this API output with Tailwind."</em> This saved time but still required manual adjustments.
  </p>

  <p class="mt-4">
    Despite the AI’s efficiency, it struggled with Eleventy-specific configurations. When I asked, <em>"How do I set up passthrough for styles in 11ty?"</em>, GPT-4o gave a general Node.js file system answer instead of modifying `.eleventy.js` correctly. GitHub Copilot was more reliable here, as it recognized the correct structure for Eleventy’s passthrough settings. Overall, AI was most useful for syntax corrections and repetitive tasks, but manual debugging and logic structuring were necessary to ensure a fully functional and optimized site.
  </p>
</div>
